{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8bPV9aEwTKC8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jFHJbjkfeepf"
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 0x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykbI8UnR6PsU"
   },
   "source": [
    "# TASK 1 (2 Points): \n",
    "\n",
    "We work with the \"Wine Recognition\" dataset. You can read more about this dataset at [https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-recognition-dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-recognition-dataset).\n",
    "\n",
    "The data is the results of a chemical analysis of wines grown in the same region in Italy by three different cultivators.\n",
    "The data is loaded below and split into `data` and `target`. `data` is a `Dataframe` that contains the result of the chemical analysis while `target`contains an integer representing the wine cultivator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "em6VCOuE6MRU"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "(data, target) = load_wine(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HJoAuMNR6MgM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xrsPKm3w6Mi-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "173    2\n",
       "174    2\n",
       "175    2\n",
       "176    2\n",
       "177    2\n",
       "Name: target, Length: 178, dtype: int32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3W5r6Se8kXW"
   },
   "source": [
    "Next, the data is split into training data and testing data.\n",
    "The training data is used to train the model while the testing data is used to evaluate the model on different data than it was trained for. You will learn later in the course why this is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "m1w8dDgw6MoO"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_eeYvZc-f_n"
   },
   "source": [
    "\n",
    "In the following, we define functions to classify the data. We use a [Decision Tree Classifier](https://scikit-learn.org/stable/modules/tree.html#tree) and a [Support Vector Classifier](https://scikit-learn.org/stable/modules/svm.html#svm-classification). You will learn later in the course how these classifiers work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pvm_zBOe-e_X"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def run_classifier(clf, X_train, y_train, X_test, y_test):\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_test_predicted = clf.predict(X_test)\n",
    "  return accuracy_score(y_test, y_test_predicted)\n",
    "\n",
    "def run_decision_tree(X_train, y_train, X_test, y_test):\n",
    "  clf = DecisionTreeClassifier(random_state=0)\n",
    "  accuracy = run_classifier(clf, X_train, y_train, X_test, y_test)\n",
    "  print(\"The accuracy of the Decision Tree classifier is\", accuracy)\n",
    "\n",
    "def run_svc(X_train, y_train, X_test, y_test):\n",
    "  clf = SVC(random_state=0)\n",
    "  accuracy = run_classifier(clf, X_train, y_train, X_test, y_test)\n",
    "  print(\"The accuracy of the Support Vector classifier is\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1MS2D8LAMpD"
   },
   "source": [
    "### Task 1a: Classify the data\n",
    "\n",
    "Classify the data by calling the two functions `run_decision_tree` and `run_svc`.\n",
    "Which classifier works better (i.e. achieves the higher accuracy)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5ToW8fx4ANZ8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Decision Tree classifier is 0.9661016949152542\n",
      "The accuracy of the Support Vector classifier is 0.711864406779661\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train, y_train, X_test, y_test)\n",
    "run_svc(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbM8OUZFBRGH"
   },
   "source": [
    "### Task 1b: Normalize the data with mean and standard deviation\n",
    "\n",
    "Normalize the training and testing data using the following formula:\n",
    "\n",
    "$$X_{normalized} = \\frac{X-\\mu_X}{\\sigma_X}$$\n",
    "\n",
    "Calculate the mean and standard deviation __on the training data__ only (also when you normalize the testing dataset).\n",
    "\n",
    "`Pandas` provides built-in functions to calculate the average and the standard deviation. For example, `X_train.mean()` returns the average value per feature in the training dataset while `X_train.std()` returns the standard deviation per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "K0qkP9TqBRft"
   },
   "outputs": [],
   "source": [
    "X_train_normalized = (X_train - X_train.mean()) / X_train.std()\n",
    "y_train_normalized = (y_train - y_train.mean()) / y_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fNuBgC6BSFt"
   },
   "source": [
    "Call the two classification functions again with the normalized data and report the changes in accuracy. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "TFg6WbmgBShk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Decision Tree classifier is 0.3389830508474576\n",
      "The accuracy of the Support Vector classifier is 0.4067796610169492\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train_normalized, y_train, X_test, y_test)\n",
    "run_svc(X_train_normalized, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_1EVF-TBS7v"
   },
   "source": [
    "### Task 1c: Repeat Task 1b with min-max Normalization\n",
    "\n",
    "Repeat the task 1b but use the following formula to normalize tha data:\n",
    "\n",
    "$$X_{normalized} = \\frac{X-X_{min}}{X_{max} - X_{min}}$$\n",
    "\n",
    "Again, calculate the mean and standard deviation __on the training data__ only (also when you normalize the testing dataset) and use the built-in function `X_train.min()` resp. `X_train.max()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "i25XenppJ7gf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.705263</td>\n",
       "      <td>0.197556</td>\n",
       "      <td>0.534759</td>\n",
       "      <td>0.309278</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.562069</td>\n",
       "      <td>0.535865</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.401899</td>\n",
       "      <td>0.227373</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.596533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.845214</td>\n",
       "      <td>0.465241</td>\n",
       "      <td>0.484536</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.082278</td>\n",
       "      <td>0.348786</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.107959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.331579</td>\n",
       "      <td>0.105906</td>\n",
       "      <td>0.331551</td>\n",
       "      <td>0.278351</td>\n",
       "      <td>0.163043</td>\n",
       "      <td>0.541379</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.427215</td>\n",
       "      <td>0.128035</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.118203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.310526</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.208556</td>\n",
       "      <td>0.319588</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.198312</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.122517</td>\n",
       "      <td>0.650407</td>\n",
       "      <td>0.659341</td>\n",
       "      <td>0.346730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.471053</td>\n",
       "      <td>0.505092</td>\n",
       "      <td>0.502674</td>\n",
       "      <td>0.458763</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.067511</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.174051</td>\n",
       "      <td>0.940397</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.175824</td>\n",
       "      <td>0.320725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.744737</td>\n",
       "      <td>0.126273</td>\n",
       "      <td>0.700535</td>\n",
       "      <td>0.742268</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.679310</td>\n",
       "      <td>0.531646</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.458861</td>\n",
       "      <td>0.181015</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.104019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.321053</td>\n",
       "      <td>0.171079</td>\n",
       "      <td>0.406417</td>\n",
       "      <td>0.432990</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.231034</td>\n",
       "      <td>0.356540</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.382911</td>\n",
       "      <td>0.183223</td>\n",
       "      <td>0.422764</td>\n",
       "      <td>0.695971</td>\n",
       "      <td>0.182821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.199593</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.072165</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.803797</td>\n",
       "      <td>0.635762</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.633700</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.436842</td>\n",
       "      <td>0.130346</td>\n",
       "      <td>0.481283</td>\n",
       "      <td>0.520619</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.236287</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.144592</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.289377</td>\n",
       "      <td>0.171001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.344737</td>\n",
       "      <td>0.317719</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.536082</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.544828</td>\n",
       "      <td>0.373418</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.281646</td>\n",
       "      <td>0.116998</td>\n",
       "      <td>0.260163</td>\n",
       "      <td>0.772894</td>\n",
       "      <td>0.126084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  malic_acid       ash  alcalinity_of_ash  magnesium  \\\n",
       "22   0.705263    0.197556  0.534759           0.309278   0.336957   \n",
       "146  0.750000    0.845214  0.465241           0.484536   0.108696   \n",
       "97   0.331579    0.105906  0.331551           0.278351   0.163043   \n",
       "69   0.310526    0.061100  0.208556           0.319588   0.880435   \n",
       "167  0.471053    0.505092  0.502674           0.458763   0.195652   \n",
       "..        ...         ...       ...                ...        ...   \n",
       "71   0.744737    0.126273  0.700535           0.742268   0.173913   \n",
       "106  0.321053    0.171079  0.406417           0.432990   0.108696   \n",
       "14   0.881579    0.199593  0.545455           0.072165   0.347826   \n",
       "92   0.436842    0.130346  0.481283           0.520619   0.108696   \n",
       "102  0.344737    0.317719  0.588235           0.536082   0.304348   \n",
       "\n",
       "     total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "22        0.562069    0.535865              0.264151         0.401899   \n",
       "146       0.000000    0.000000              0.509434         0.082278   \n",
       "97        0.541379    0.455696              0.301887         0.427215   \n",
       "69        0.300000    0.198312              0.018868         0.658228   \n",
       "167       0.172414    0.067511              0.509434         0.174051   \n",
       "..             ...         ...                   ...              ...   \n",
       "71        0.679310    0.531646              0.150943         0.458861   \n",
       "106       0.231034    0.356540              0.452830         0.382911   \n",
       "14        0.800000    0.696203              0.301887         0.803797   \n",
       "92        0.137931    0.236287              0.849057         0.379747   \n",
       "102       0.544828    0.373418              0.396226         0.281646   \n",
       "\n",
       "     color_intensity       hue  od280/od315_of_diluted_wines   proline  \n",
       "22          0.227373  0.512195                      1.000000  0.596533  \n",
       "146         0.348786  0.081301                      0.021978  0.107959  \n",
       "97          0.128035  0.609756                      0.538462  0.118203  \n",
       "69          0.122517  0.650407                      0.659341  0.346730  \n",
       "167         0.940397  0.195122                      0.175824  0.320725  \n",
       "..               ...       ...                           ...       ...  \n",
       "71          0.181015  0.715447                      0.692308  0.104019  \n",
       "106         0.183223  0.422764                      0.695971  0.182821  \n",
       "14          0.635762  0.585366                      0.633700  1.000000  \n",
       "92          0.144592  0.390244                      0.289377  0.171001  \n",
       "102         0.116998  0.260163                      0.772894  0.126084  \n",
       "\n",
       "[119 rows x 13 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normalized_minmax = (X_train - X_train.min()) / (X_train.max() - X_train.min())\n",
    "X_train_normalized_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIy0ECbTJ7gq"
   },
   "source": [
    "Call the two classification functions again with the normalized data and report the changes in accuracy. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "99uuR7ngJ7gr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Decision Tree classifier is 0.3389830508474576\n",
      "The accuracy of the Support Vector classifier is 0.4067796610169492\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train_normalized_minmax, y_train, X_test, y_test)\n",
    "run_svc(X_train_normalized_minmax, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_i1aBh6KnWw"
   },
   "source": [
    "## 📢 **HAND-IN** 📢: Report on Moodle whether you solved this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7I1RBjQK7Ly"
   },
   "source": [
    "---\n",
    "# TASK 2 (2 Points): \n",
    "\n",
    "In Task 1 we clearly saw that normalization improves the result for Support Vector Classifiers but not for Decision Trees. You will learn later in the course why Decision Trees don't need normalization.\n",
    "\n",
    "However, to better understand the influence of normalization, we will plot the data with and without normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "w9qp3e4nBTPK"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnF26SbCNCRS"
   },
   "source": [
    "### Task 2a: Plot the unnormalized data\n",
    "\n",
    "For simplicity, we only consider only the columns `alcohol` and `malic_acid` from the training dataset.\n",
    "\n",
    "Create a [Scatterplot](https://seaborn.pydata.org/generated/seaborn.scatterplot.html) from the data with  the attribute `alcohol` on the `x`-axis and `malic_acid` on the `y`-axis.\n",
    "\n",
    "Plot the un-normalized data `X_train` as well as the two noramlized versions from Exercise 1 in the same plot and describe what happens.\n",
    "\n",
    "__Hint:__ To visualize the data distribution in the same plot just call `sns.scatterplot` three times within the same code-cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-lc07hbiOvYu"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `malic_acid` for parameter `y`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6424/1070418433.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"alcohol\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"malic_acid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_normalized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malcohol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmalic_acid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_normalized_minmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malcohol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmalic_acid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\relational.py\u001b[0m in \u001b[0;36mscatterplot\u001b[1;34m(x, y, hue, style, size, data, palette, hue_order, hue_norm, sizes, size_order, size_norm, markers, style_order, x_bins, y_bins, units, estimator, ci, n_boot, alpha, x_jitter, y_jitter, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ScatterPlotter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_semantics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m     p = _ScatterPlotter(\n\u001b[0m\u001b[0;32m    809\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[0mx_bins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_bins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_bins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_bins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\relational.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, variables, x_bins, y_bins, estimator, ci, n_boot, alpha, x_jitter, y_jitter, legend)\u001b[0m\n\u001b[0;32m    585\u001b[0m         )\n\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_semantic_mappings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36massign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"long\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m             plot_data, variables = self._assign_variables_longform(\n\u001b[0m\u001b[0;32m    669\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36m_assign_variables_longform\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"Could not interpret value `{val}` for parameter `{key}`\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret value `malic_acid` for parameter `y`"
     ]
    }
   ],
   "source": [
    "sns.scatterplot(X_train, x = alcohol, y = malic_acid)\n",
    "sns.scatterplot(X_train_normalized, x = alcohol, y = malic_acid)\n",
    "sns.scatterplot(X_train_normalized_minmax, x = alcohol, y = malic_acid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJ5Ncd5cN-9z"
   },
   "source": [
    "We will now have a closer look at the data. Calculate for the un-normalized data as well as for the two normalized versions of data\n",
    "\n",
    "- The average value in the column `avg(alcohol)`\n",
    "- The standard deviation in the column `std(alcohol)`\n",
    "- The minimum value in the column `min(alcohol)`\n",
    "- The maxmium value in the column `max(alcohol)`\n",
    "- The range in the column by subtracting the minimum of the maximum in the column `max(alcohol) - min(alcohol)`\n",
    "\n",
    "Compare the properties of the un-normalized data with the normalized data. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3D06pyKQjGq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AH7H07ZcSniv"
   },
   "source": [
    "## 📢 **HAND-IN** 📢: Report on Moodle whether you solved this task.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UT3_BLJDl-0o"
   },
   "source": [
    "# TASK 3 (6 Points): Binning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7K4Cikz4aZE"
   },
   "source": [
    "The following list consists of the age of several people: \n",
    "```python\n",
    "[13, 15, 16, 18, 19, 20, 20, 21, 22, 22, 25, 25, 26, 26, 30, 33, 34, 35, 35, 35, 36, 37, 40, 42, 46, 53, 70]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsHmNGlW4aZE"
   },
   "source": [
    "### Task 3a: Equal-Width Binning\n",
    "Apply binning to the dataset using 3 equal-width bins. Smooth the data using the mean of the bins.\n",
    "\n",
    "Tips:\n",
    "1. Calculate the size of the bins\n",
    "2. Assign each value to the corresponding bin\n",
    "3. Calculate the mean per bin\n",
    "4. Replace each value by the mean of its bin\n",
    "\n",
    "__Solve this exercise by hand without using Python__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eukBUnVs4aZE"
   },
   "source": [
    "❗ TODO ❗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UL9OUG44aZF"
   },
   "source": [
    "###Task 3b: Equal-Depth Binning\n",
    "\n",
    "Apply binning to the dataset using 3 equal-depth bins. Smooth the data using the mean of the bins. Explain the steps of your approach and give the final result.\n",
    "\n",
    "Tips:\n",
    "1. Calculate the number of elements per bin\n",
    "2. Assign each value to the corresponding bin\n",
    "3. Calculate the mean per bin\n",
    "4. Replace each value by the mean of its bin\n",
    "\n",
    "__Please solve this exercise by hand without using Python__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vhf3wkSm4aZF"
   },
   "source": [
    "\n",
    "❗ TODO ❗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex21HuPTl_Qx"
   },
   "source": [
    "## 📢 **HAND-IN** 📢: Describe on Moodle the results of Exercise 3: \n",
    "\n",
    "* Copy the results of Exercise 3a and 3b to Moodle\n",
    "* Describe the differences between task 3a and task 3b\n",
    "* Describe situations when binning should be used and give a concrete example. Are there also circumstances in which binning should not be applied?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
